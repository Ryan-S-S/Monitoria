{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14392,
     "status": "ok",
     "timestamp": 1746056870209,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "RB6KNJ8bDwl1"
   },
   "outputs": [],
   "source": [
    "# Instalar bibliotecas necessárias (se não tiver)\n",
    "# !pip install pandas torch torchvision matplotlib scikit-learn opencv-python\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18900,
     "status": "ok",
     "timestamp": 1746056889204,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "TmcCsSohD2Cc",
    "outputId": "1a731fb2-180c-4f01-80a7-465dcfdc5d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando o dataset...\n",
      "--2025-04-30 23:47:48--  https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\n",
      "Resolving download.microsoft.com (download.microsoft.com)... 23.75.210.62, 2600:1406:cc00:284::317f, 2600:1406:cc00:289::317f\n",
      "Connecting to download.microsoft.com (download.microsoft.com)|23.75.210.62|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 824887076 (787M) [application/octet-stream]\n",
      "Saving to: ‘kagglecatsanddogs_5340.zip’\n",
      "\n",
      "kagglecatsanddogs_5 100%[===================>] 786.67M  57.2MB/s    in 9.2s    \n",
      "\n",
      "2025-04-30 23:47:58 (85.2 MB/s) - ‘kagglecatsanddogs_5340.zip’ saved [824887076/824887076]\n",
      "\n",
      "Download completo.\n",
      "Extraindo o dataset...\n",
      "Extração completa.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Baixar e Extrair o Dataset ---\n",
    "# Se você estiver rodando em Google Colab ou ambiente similar, isso funciona.\n",
    "# Se estiver em um script local, pode precisar adaptar.\n",
    "print(\"Baixando o dataset...\")\n",
    "# Verifica se o arquivo zip já existe para evitar download duplicado\n",
    "if not os.path.exists('kagglecatsanddogs_5340.zip'):\n",
    "    !wget https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip\n",
    "    print(\"Download completo.\")\n",
    "else:\n",
    "    print(\"Arquivo zip já existe.\")\n",
    "\n",
    "# Verifica se a pasta PetImages já existe para evitar extração duplicada\n",
    "if not os.path.exists('PetImages'):\n",
    "    print(\"Extraindo o dataset...\")\n",
    "    with zipfile.ZipFile('kagglecatsanddogs_5340.zip', 'r') as zip_ref:\n",
    "        # Extrair apenas as pastas Cat e Dog, pois __MACOSX pode causar problemas\n",
    "        for member in zip_ref.namelist():\n",
    "            if \"PetImages/Cat/\" in member or \"PetImages/Dog/\" in member:\n",
    "                 zip_ref.extract(member, '.')\n",
    "    print(\"Extração completa.\")\n",
    "else:\n",
    "    print(\"Pasta PetImages já existe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2335,
     "status": "ok",
     "timestamp": 1746056891545,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "Zp0EBaNQF2Rv",
    "outputId": "6478bc67-81d0-4816-dac1-a47fc9fbce51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizando os dados...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verificando Cats: 100%|██████████| 12501/12501 [00:01<00:00, 10285.24it/s]\n",
      "Verificando Dogs:  29%|██▉       | 3644/12501 [00:00<00:00, 12152.69it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "Verificando Dogs: 100%|██████████| 12501/12501 [00:01<00:00, 11811.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens encontradas: 24998\n",
      "Total de imagens corrompidas ignoradas: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Organizar os Dados ---\n",
    "print(\"Organizando os dados...\")\n",
    "base_dir = 'PetImages'\n",
    "categories = ['Cat', 'Dog']\n",
    "image_paths = []\n",
    "labels = []\n",
    "corrupted_images = [] # Lista para armazenar caminhos de imagens corrompidas\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(base_dir, category)\n",
    "    # Usamos tqdm para ver o progresso ao listar e verificar imagens\n",
    "    for img_name in tqdm(os.listdir(path), desc=f\"Verificando {category}s\"):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        # --- 4. Tratar Imagens Corrompidas ---\n",
    "        try:\n",
    "            # Tenta abrir a imagem. Se der erro, é provável que esteja corrompida.\n",
    "            # O .verify() checa a integridade, mas pode não pegar todos os casos.\n",
    "            # Abrir e fechar é mais robusto.\n",
    "            img = Image.open(img_path)\n",
    "            img.verify() # Verifica a integridade do arquivo\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(0 if category == 'Cat' else 1) # 0 para Gato, 1 para Cachorro\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            #print(f\"Imagem corrompida ou ilegível: {img_path}. Erro: {e}\")\n",
    "            corrupted_images.append(img_path)\n",
    "            # Pass (ignora a imagem corrompida)\n",
    "\n",
    "print(f\"Total de imagens encontradas: {len(image_paths)}\")\n",
    "print(f\"Total de imagens corrompidas ignoradas: {len(corrupted_images)}\")\n",
    "\n",
    "# Criar um DataFrame pandas\n",
    "df = pd.DataFrame({'path': image_paths, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1746056891571,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "_KljsEsiF56v",
    "outputId": "fa4fdb27-938d-4fcc-e945-437e80997edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de imagens para treino: 19998\n",
      "Número de imagens para validação: 5000\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Dividir os Dados ---\n",
    "# Usar train_test_split para dividir em treino e validação (ex: 80% treino, 20% validação)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "print(f\"\\nNúmero de imagens para treino: {len(train_df)}\")\n",
    "print(f\"Número de imagens para validação: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1746056891587,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "EWEUUrPnF8r_"
   },
   "outputs": [],
   "source": [
    "# --- 5. Criar um Dataset Customizado ---\n",
    "class PetImagesDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "\n",
    "        try:\n",
    "            # Abrir a imagem\n",
    "            image = Image.open(img_path).convert('RGB') # Garantir que é RGB (3 canais)\n",
    "            # Aplicar transformações\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "             # Em caso de erro inesperado ao carregar/transformar, retorna None\n",
    "             # Isso é uma forma simples; em treino real, pode-se ter estratégias mais robustas\n",
    "             #print(f\"Erro ao carregar/transformar imagem {img_path}: {e}\")\n",
    "             return None, None # Retorna None para sinalizar problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746056891602,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "U6sbFdpiGBER"
   },
   "outputs": [],
   "source": [
    "# --- 6. Definir Transformações ---\n",
    "# Transformações para treino (inclui aumento de dados)\n",
    "# Resize para um tamanho um pouco maior, depois RandomCrop para o tamanho final\n",
    "# ToTensor converte a imagem PIL para Tensor e escala os pixels para [0, 1]\n",
    "# Normalize usa médias e desvios padrões comuns (ex: ImageNet)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((70, 70)),\n",
    "    transforms.RandomCrop((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(), # Aumento de dados: vira horizontalmente aleatoriamente\n",
    "    transforms.ToTensor(),\n",
    "    # Valores de normalização comuns (médias e desvios padrões por canal RGB)\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Transformações para validação (apenas redimensionar e normalizar)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), # Redimensiona diretamente para o tamanho final\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "\n",
    "# Criar instâncias dos Datasets\n",
    "train_dataset = PetImagesDataset(train_df, transform=train_transform)\n",
    "val_dataset = PetImagesDataset(val_df, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746056891623,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "A5_hseqfGD7H"
   },
   "outputs": [],
   "source": [
    "# --- 7. Criar DataLoaders ---\n",
    "# DataLoaders ajudam a carregar os dados em batches e embaralhar (no treino)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Função para lidar com amostras None no DataLoader (devido a imagens corrompidas tratadas)\n",
    "def collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x[0] is not None, batch)) # Remove None tuples\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construir o Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1746056891708,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "59J_ksO6GLCx"
   },
   "outputs": [],
   "source": [
    "# --- 8. Definir o Modelo (CNN Simples) ---\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=1): # 1 classe de saída para classificação binária com BCEWithLogitsLoss\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Camada Convolucional 1\n",
    "        # Entrada: 3 canais (RGB), Saída: 32 canais, Kernel: 3x3\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # Diminui a dimensão espacial pela metade\n",
    "\n",
    "        # Camada Convolucional 2\n",
    "        # Entrada: 32 canais, Saída: 64 canais, Kernel: 3x3\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # Diminui a dimensão espacial pela metade\n",
    "\n",
    "        # Camada Convolucional 3\n",
    "        # Entrada: 64 canais, Saída: 128 canais, Kernel: 3x3\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # Diminui a dimensão espacial pela metade\n",
    "\n",
    "        # Camadas Totalmente Conectadas (Fully Connected / Dense)\n",
    "        # Após as camadas de pooling, a dimensão da imagem 64x64 -> 32x32 -> 16x16 -> 8x8\n",
    "        # Temos 128 canais, então 128 * 8 * 8 = 8192 features antes da primeira camada FC\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5) # Dropout para regularização\n",
    "        self.fc2 = nn.Linear(512, num_classes) # Saída: 1 neurônio para classificação binária\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "\n",
    "        # Achatar (flatten) os dados antes das camadas totalmente conectadas\n",
    "        x = x.view(-1, 128 * 8 * 8) # -1 infere o tamanho do batch size\n",
    "\n",
    "        x = self.dropout(self.relu4(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = SimpleCNN(num_classes=1)\n",
    "\n",
    "# --- Configurar Dispositivo (CPU ou GPU) ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# --- 8. Configurar Função de Perda e Otimizador ---\n",
    "# BCEWithLogitsLoss é boa para classificação binária, combina Sigmoid + Binary Cross Entropy\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Otimizador Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykB1ir-dGO9G",
    "outputId": "24560017-a709-43fb-a8b3-c586749538a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo de modelo encontrado em best_cats_vs_dogs_model.pth. Carregando...\n",
      "Erro ao carregar o modelo de best_cats_vs_dogs_model.pth. Começando do zero. Erro: 'model_state_dict'\n",
      "\n",
      "Iniciando o treinamento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 1/10 [Treino]:   7%|▋         | 46/625 [00:32<03:46,  2.56it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "Época 1/10 [Treino]: 100%|██████████| 625/625 [04:40<00:00,  2.23it/s]\n",
      "Época 1/10 [Validação]: 100%|██████████| 157/157 [00:32<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Salvo novo melhor modelo (checkpoint) em best_cats_vs_dogs_model.pth com Acurácia de Validação: 0.8824\n",
      "Época [1/10], Perda de Treino: 0.2319, Perda de Validação: 0.2788, Acurácia de Validação: 0.8824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 2/10 [Treino]:   3%|▎         | 18/625 [00:08<04:21,  2.32it/s]/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "Época 2/10 [Treino]:   3%|▎         | 20/625 [00:08<04:09,  2.43it/s]"
     ]
    }
   ],
   "source": [
    "import os # ADIÇÃO: Importar o módulo os para verificar a existência do arquivo\n",
    "# ... (outros imports e código anterior: dataset, dataloaders, model, criterion, optimizer, device) ...\n",
    "\n",
    "\n",
    "# --- 9. Treinar o Modelo ---\n",
    "# Se você carregar um modelo salvo na época 5 e NUM_EPOCHS for 10, ele rodará até a época 9 (totalizando 10).\n",
    "TOTAL_NUM_EPOCHS = 10\n",
    "NUM_EPOCHS = TOTAL_NUM_EPOCHS\n",
    "\n",
    "# --- Configurar Salvamento do Melhor Modelo ---\n",
    "#best_accuracy = -1.0 # Removido: best_accuracy será carregada ou inicializada depois\n",
    "best_model_path = 'best_cats_vs_dogs_model.pth' # Nome do arquivo onde o modelo será salvo/carregado\n",
    "\n",
    "# ADIÇÃO: Inicializar a época de início do treinamento\n",
    "start_epoch = 0\n",
    "# ADIÇÃO: Inicializar a melhor acurácia (será substituída se um modelo for carregado)\n",
    "best_accuracy = -1.0 # ADIÇÃO: Inicializa aqui, antes da tentativa de carregar\n",
    "\n",
    "# ADIÇÃO: --- Lógica para Carregar o Modelo Salvo (se existir) ---\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"Arquivo de modelo encontrado em {best_model_path}. Carregando...\")\n",
    "    try:\n",
    "        # Carregar o checkpoint (inclui estado do modelo, otimizador, época e melhor acurácia)\n",
    "        checkpoint = torch.load(best_model_path, map_location=device)\n",
    "\n",
    "        # Carregar o estado do modelo\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # Carregar o estado do otimizador (importante para continuar o treinamento)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        # Carregar a melhor acurácia salva\n",
    "        best_accuracy = checkpoint['best_accuracy']\n",
    "\n",
    "        # Definir a época de início para continuar de onde parou\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "        print(f\"Modelo e otimizador carregados com sucesso. Retomando o treinamento a partir da Época {start_epoch}.\")\n",
    "        print(f\"Melhor acurácia de validação prévia: {best_accuracy:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar o modelo de {best_model_path}. Começando do zero. Erro: {e}\")\n",
    "        # Se houver erro ao carregar, start_epoch e best_accuracy permanecem nos valores iniciais (0 e -1.0)\n",
    "else:\n",
    "    print(f\"Nenhum arquivo de modelo encontrado em {best_model_path}. Iniciando treinamento do zero.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Treinamento---\n",
    "print(\"\\nIniciando o treinamento...\")\n",
    "# ADIÇÃO: Mudar o range do loop para começar da 'start_epoch'\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    model.train() # Coloca o modelo em modo de treino (habilita dropout, etc.)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Loop sobre os batches do treino\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Época {epoch+1}/{NUM_EPOCHS} [Treino]\"): # ADIÇÃO: Ajusta o desc para mostrar o número correto da época\n",
    "        # Mover dados para o dispositivo correto (CPU/GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float().unsqueeze(1) # labels precisam ser float e ter a mesma dimensão da saída do modelo\n",
    "\n",
    "        # Zerar os gradientes do otimizador\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calcular a perda\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass e otimização\n",
    "        loss.backward() # Calcula os gradientes\n",
    "        optimizer.step() # Atualiza os pesos\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    # ADIÇÃO: Calcula a perda média da época (melhor fora do tqdm)\n",
    "    # Removido: epoch_loss = running_loss / len(train_loader.dataset) # Movido para fora do loop do loader\n",
    "\n",
    "    # --- Avaliação no conjunto de validação após cada época ---\n",
    "    model.eval() # Coloca o modelo em modo de avaliação (desabilita dropout, etc.)\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad(): # Desabilita o cálculo de gradientes na avaliação\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Época {epoch+1}/{NUM_EPOCHS} [Validação]\"): # ADIÇÃO: Ajusta o desc para mostrar o número correto da época\n",
    "            # Mover dados para o dispositivo correto\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calcular a perda de validação\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calcular acurácia\n",
    "            predicted = torch.round(torch.sigmoid(outputs))\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # ADIÇÃO: Calcula métricas da época (melhor fora do tqdm)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset) # ADIÇÃO: Movido para cá\n",
    "    epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "\n",
    "    # --- Lógica para Salvar o Melhor Modelo (Checkpoint Completo) ---\n",
    "    # Se a acurácia nesta época for maior que a melhor acurácia vista até agora\n",
    "    if epoch_accuracy > best_accuracy:\n",
    "        best_accuracy = epoch_accuracy # Atualiza a melhor acurácia\n",
    "        # ADIÇÃO: Salva um dicionário (checkpoint) com mais informações\n",
    "        checkpoint = {\n",
    "            'epoch': epoch, # ADIÇÃO: Salva a época atual\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(), # ADIÇÃO: Salva o estado do otimizador\n",
    "            'best_accuracy': best_accuracy # ADIÇÃO: Salva a melhor acurácia encontrada\n",
    "        }\n",
    "        torch.save(checkpoint, best_model_path)\n",
    "        print(f\"-> Salvo novo melhor modelo (checkpoint) em {best_model_path} com Acurácia de Validação: {best_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    print(f\"Época [{epoch+1}/{NUM_EPOCHS}], Perda de Treino: {epoch_loss:.4f}, Perda de Validação: {epoch_val_loss:.4f}, Acurácia de Validação: {epoch_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nTreinamento finalizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação e Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28541,
     "status": "ok",
     "timestamp": 1746066520664,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "mPI6iGXkDdtf",
    "outputId": "217fa263-974f-4f2c-c920-e6f7a519f583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliação final no conjunto de validação...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avaliando: 100%|██████████| 157/157 [00:28<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perda Final de Validação: 0.2819\n",
      "Acurácia Final de Validação: 0.8886\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat       0.90      0.88      0.89      2500\n",
      "         Dog       0.88      0.90      0.89      2500\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.89      0.89      0.89      5000\n",
      "weighted avg       0.89      0.89      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 10. Avaliação Final ---\n",
    "print(\"\\nAvaliação final no conjunto de validação...\")\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader, desc=\"Avaliando\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "\n",
    "        predicted = torch.round(torch.sigmoid(outputs))\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "\n",
    "final_val_loss = val_loss / len(val_loader.dataset)\n",
    "final_accuracy = correct_predictions / total_samples\n",
    "\n",
    "print(f\"Perda Final de Validação: {final_val_loss:.4f}\")\n",
    "print(f\"Acurácia Final de Validação: {final_accuracy:.4f}\")\n",
    "\n",
    "# Você pode gerar um relatório de classificação mais detalhado se quiser\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(all_labels, all_predictions, target_names=['Cat', 'Dog']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de Imagem própria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1746062066030,
     "user": {
      "displayName": "Ryan Souza Santana",
      "userId": "06894951986616193054"
     },
     "user_tz": 180
    },
    "id": "WLP7SLrQZLPD",
    "outputId": "05d584ed-a643-4d4c-b011-2c7dce2b99e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Análise da imagem: /content/Cachorro.jpg\n",
      "Probabilidade (Dog): 0.9951\n",
      "Probabilidade (Cat): 0.0049\n",
      "O modelo prevê que a imagem é um: Dog\n"
     ]
    }
   ],
   "source": [
    "# --- Bloco para Testar com uma Foto Única ---\n",
    "\n",
    "# 1. Defina o caminho para a sua foto\n",
    "caminho_da_sua_foto = '/content/Cachorro.jpg'\n",
    "\n",
    "# Verifique se o arquivo existe\n",
    "if not os.path.exists(caminho_da_sua_foto):\n",
    "    print(f\"Erro: Arquivo não encontrado em {caminho_da_sua_foto}\")\n",
    "else:\n",
    "    try:\n",
    "        # 2. Carregar a imagem\n",
    "        imagem = Image.open(caminho_da_sua_foto).convert('RGB') # Garante 3 canais\n",
    "\n",
    "        # 3. Aplicar as transformações de validação\n",
    "        # Certifique-se que 'val_transform' está definida e é a mesma usada na avaliação\n",
    "        imagem_tensor = val_transform(imagem)\n",
    "\n",
    "        # 4. Preparar o tensor para o modelo\n",
    "        # O modelo espera um batch, mesmo que seja de 1 imagem. unsqueeze(0) adiciona a dimensão do batch.\n",
    "        imagem_tensor = imagem_tensor.unsqueeze(0) # Adiciona uma dimensão no início (batch size = 1)\n",
    "        imagem_tensor = imagem_tensor.to(device)   # Mover o tensor para o mesmo dispositivo do modelo\n",
    "\n",
    "        # 5. Colocar o modelo em modo de avaliação\n",
    "        model.eval()\n",
    "\n",
    "        # 6. Passar a imagem pelo modelo e 7. Interpretar a saída\n",
    "        with torch.no_grad(): # Desabilita o cálculo de gradientes para inferência (mais rápido e economiza memória)\n",
    "            output = model(imagem_tensor)\n",
    "\n",
    "            # A saída do modelo são logits. Para classificação binária com BCEWithLogitsLoss,\n",
    "            # aplicamos Sigmoid para obter a probabilidade e depois arredondamos para a classe\n",
    "            probability = torch.sigmoid(output).item() # .item() pega o valor escalar do tensor\n",
    "\n",
    "            # Se a probabilidade for >= 0.5, prevemos 1 (Cachorro), caso contrário 0 (Gato)\n",
    "            predicted_class_index = round(probability)\n",
    "\n",
    "            # Mapear o índice de volta para o nome da classe\n",
    "            predicted_class_name = \"Dog\" if predicted_class_index == 1 else \"Cat\"\n",
    "\n",
    "        # Exibir o resultado\n",
    "        print(f\"\\nAnálise da imagem: {caminho_da_sua_foto}\")\n",
    "        print(f\"Probabilidade (Dog): {probability:.4f}\")\n",
    "        print(f\"Probabilidade (Cat): {1 - probability:.4f}\") # Probabilidade de Cat é 1 - Probabilidade de Dog\n",
    "        print(f\"O modelo prevê que a imagem é um: {predicted_class_name}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: Arquivo não encontrado em {caminho_da_sua_foto}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao processar a imagem: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPv7dDLh9SDixugpE3ahPuj",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
